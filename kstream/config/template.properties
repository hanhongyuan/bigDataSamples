####################################################
#### 数据格式解析错误会产生一条WARN日志,不会关闭server
#### 配置文件格式错误以及不支持的操作会退出server
#### 多值使用半角逗号隔开，下不赘述
#### 多条件使用半角分号隔开，下不赘述
#### 【list】表示可多值
#### 【multi con】表示可多条件
################### data source ####################
#### key,value均为string,且value为json格式
source.topic.name=
####################################################
##################### dicSet #######################
#### filter,mapper等操作使用的字典
#### 暂只支持kafka
dic.type=kafka
#### dic映射的字段名【list】。注意：这个配置意味着执行字段缓存操作.如:f1,f2...
dic.fields=
#### 存储对应kafka中的topic，与fields对应【list】.如:t1,t2...
dic.kafka.topics=
####################################################
##################### order #######################
#### filter,mapper,window执行顺序,半角逗号分隔。仅表示顺序，不代表三个操作都必须配置执行。默认mapper,filter,window
action.order=mapper,filter,window
####################################################
##################### filter #######################
#### 过滤字段操作暂支持(in,notIn)【list】.如:in,notIn...
filter.actions=in
#### 过滤字段列【list】与actions对应。注意：这个配置意味着要进行filter操作.如:k1,k2...
filter.keys=
####################################################
##################### mapper #######################
#### 注意：mapper操作后慎重选择window操作，可能mapper添加标签的记录会被window聚合操作覆盖。
#### 转换映射操作暂支持(in,notIn)【list】【multi con】如:in,notIn,in;notIn,in...
mapper.actions=in
#### 转换映射字段列【list】【multi con】。注意：这个配置意味着要进行mapper操作.如:k1,k2,k3;j1,j2....
mapper.keys=
#### 打标签之类功能，输出value中添加满足条件的KV对【multi con】。注意：输出字段配置是all或者添加进去，否则最后输出会过滤掉
#### 上面actions与keys对应，一个转换映射对应下面的一个append,值为半角冒号隔开的键值对,如:k1:v1;k2:v2...
mapper.append=
####################################################
################# window aggregation ###############
#### 分组的字段列【list】。注意：这个配置意味着要进行window aggregation操作.如:f1,f2,f3...
window.keys=
#### window size(millisecond unit)。默认600000
#window.sizeMs=600000
#### default window size
#window.advanceMs=
#### default window size
#window.retentionMs=
#### 自定义事件时间,字段列名，默认record的timestamp。注意：这个配置意味着使用自定义的event time
window.time.name=
#### 自定义时间值类型long或string(需要配置format)
window.time.value.type=
#### 自定义时间值类型string时需要配置转换格式
window.time.formatter=
#### locale language ENGLISH("en"),FRENCH("fr"),GERMAN("de"),ITALIAN("it"),
#### JAPANESE("ja"),KOREAN("ko"),CHINESE("zh")...默认en
#window.time.locale.lang=en
#### string ID of a ZoneOffset,如:+h,+hh,+hh:mm,-hh:mm,+hhmm,-hhmm,+hh:mm:ss,-hh:mm:ss,+hhmmss,-hhmmss
#### string时间格式的时区。默认东八区
#window.time.offsetId=+08:00
#### 窗口聚合运算统计出值的field名称，添加在输出的value中。注意：输出字段配置是all或者添加进去，否则最后输出会过滤掉
window.count=window_count
#### 窗口起始时间field名称，可选择是否输出(未配置则不输出)。注意：输出字段配置是all或者添加进去，否则最后输出会过滤掉
window.startTime=window_start
#### 窗口结束时间field名称，可选择是否输出(未配置则不输出)。注意：输出字段配置是all或者添加进去，否则最后输出会过滤掉
window.endTime=window_end
#### queryable store name,valid characters are ASCII alphanumerics, '.', '_' and '-'
#window.store.name=aggregation
####################################################
################### output source ##################
#### output fields【list】或者输出所有(all).如:f1,f2,f3...默认all
#### 注意：如果配置的f不存在，输出会增加f,值为null
output.keys=all
#### 输出值得type,支持json,custom.默认json
output.value.type=
#### custom style 例:{“columns”:["数量"],"index":["$window_start$"],"data":[["$window_count$"]]}
#### 注意:替换值前后加上$，如果替换字段输出value不存在，则不会被替换(可以output keys中配置，如果不存在会新增此field,值null)。
output.value.custom.style={“columns”:["数量"],"index":["$window_start$"],"data":[["$window_count$"]]}
#### kafka,zbus...
output.type=kafka
#### 输出kafka的topic名称，启动前需要此topic已存在(或者kafka配置文件中允许自动创建topic)
output.kafka.topic=
#### zbus地址
output.zbus.address=
#### zbus mq名称
output.zbus.mq=
#### unix时间戳field【list】.注意：这个配置意味着要对输出的字段做时间转换操作操作.如:f1,f2,f3...
output.time.name=
#### 时间戳类型type,long,string.【list】
output.time.value.type=long,string
#### type是string数据的格式。若全是long，可不配置。【list】
#### field,type,in_format一一对应。如：type[long,string],format[,yyyy-MM-dd]
#### 注意：long,string同时存在，format对应的long要添加半角逗号
output.time.in.formatter=,uuuu-MM-dd HH:mm:ss.SSS
#### 转换输出的时间格式.默认'uuuu-MM-dd HH:mm:ss.SSS'
output.time.out.formatter=uuuu-MM-dd
#### 默认东八区+08:00
#output.time.offsetId=+08:00
#### 具体信息可参看window.time.默认en.in和out暂时lang都用下面这个配置
#output.time.locale.lang=en
#####################################################
############### kafka stream config #################
#### 可以自定义添加kstream支持的配置属性,名称要与官方定义一致。下方列出的为必须配置项
application.id=
bootstrap.servers=localhost:9092
#### earliest,latest.默认earliest
#auto.offset.reset=earliest
#### 调用stream的线程数
#num.stream.threads=1
#### 所有线程的缓存，配置过小聚合结果存在过程记录,如果要全部的过程记录，可将值设为0
#cache.max.bytes.buffering=10485760
#### 暂时默认即为String，其他有待后续添加
#default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
#default.value.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
